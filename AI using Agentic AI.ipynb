{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbd36809-1f17-42ac-a558-0d409bae24d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from collections import deque\n",
    "\n",
    "# define stock symbol and time period\n",
    "symbol = \"AAPL\"\n",
    "start_date = \"2020-01-01\"\n",
    "end_date = \"2025-02-14\"\n",
    "\n",
    "# download historical data\n",
    "data = yf.download(symbol, start=start_date, end=end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "296dadbe-c5b7-4cf2-b5de-96cac6e89728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\hp\\onedrive - iitkgp.ac.in\\documents\\data\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\hp\\onedrive - iitkgp.ac.in\\documents\\data\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\hp\\onedrive - iitkgp.ac.in\\documents\\data\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\onedrive - iitkgp.ac.in\\documents\\data\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\hp\\onedrive - iitkgp.ac.in\\documents\\data\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\hp\\onedrive - iitkgp.ac.in\\documents\\data\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\onedrive - iitkgp.ac.in\\documents\\data\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hp\\onedrive - iitkgp.ac.in\\documents\\data\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\onedrive - iitkgp.ac.in\\documents\\data\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\hp\\onedrive - iitkgp.ac.in\\documents\\data\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hp\\onedrive - iitkgp.ac.in\\documents\\data\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\onedrive - iitkgp.ac.in\\documents\\data\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\hp\\onedrive - iitkgp.ac.in\\documents\\data\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\onedrive - iitkgp.ac.in\\documents\\data\\lib\\site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\HP\\OneDrive - iitkgp.ac.in\\Documents\\Data\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\HP\\OneDrive - iitkgp.ac.in\\Documents\\Data\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\HP\\OneDrive - iitkgp.ac.in\\Documents\\Data\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f0106f8-c4aa-419c-9e2b-df001f4aea68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from collections import deque\n",
    "\n",
    "# define stock symbol and time period\n",
    "symbol = \"AAPL\"\n",
    "start_date = \"2020-01-01\"\n",
    "end_date = \"2025-02-14\"\n",
    "\n",
    "# download historical data\n",
    "data = yf.download(symbol, start=start_date, end=end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7134eb83-b0ac-48b9-9c81-d67ba576e88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering\n",
    "data['SMA_5'] = data['Close'].rolling(window=5).mean()\n",
    "data['SMA_20'] = data['Close'].rolling(window=20).mean()\n",
    "data['Returns'] = data['Close'].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77e94db8-fc01-474c-99b8-f0271a077c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NaN values and reset index\n",
    "data.dropna(inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2591df71-88bc-4112-bd3e-2b9c8c3dc757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define action space\n",
    "ACTIONS = {0: \"HOLD\", 1: \"BUY\", 2: \"SELL\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ee07a2e-652d-4bc7-8811-18d1e4801403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get state function\n",
    "def get_state(data, index):\n",
    "    return np.array([\n",
    "        float(data.loc[index, 'Close']),\n",
    "        float(data.loc[index, 'SMA_5']),\n",
    "        float(data.loc[index, 'SMA_20']),\n",
    "        float(data.loc[index, 'Returns'])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "551f7668-37d0-4e5b-a682-c9982640f419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trading environment\n",
    "class TradingEnvironment:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.initial_balance = 10000\n",
    "        self.balance = self.initial_balance\n",
    "        self.holdings = 0\n",
    "        self.index = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.balance = self.initial_balance\n",
    "        self.holdings = 0\n",
    "        self.index = 0\n",
    "        return get_state(self.data, self.index)\n",
    "\n",
    "    def step(self, action):\n",
    "        price = float(self.data.loc[self.index, 'Close'])\n",
    "        reward = 0\n",
    "\n",
    "        if action == 1 and self.balance >= price:  # BUY\n",
    "            self.holdings = self.balance // price\n",
    "            self.balance -= self.holdings * price\n",
    "        elif action == 2 and self.holdings > 0:  # SELL\n",
    "            self.balance += self.holdings * price\n",
    "            self.holdings = 0\n",
    "\n",
    "        self.index += 1\n",
    "        done = self.index >= len(self.data) - 1\n",
    "\n",
    "        if done:\n",
    "            reward = self.balance - self.initial_balance\n",
    "\n",
    "        next_state = get_state(self.data, self.index) if not done else None\n",
    "        return next_state, reward, done, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48cff85e-6e4f-4846-b9c5-fe725f9b06d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep q-network\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, action_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c35353f-32ca-4ba1-894c-2e1c5138464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQN agent\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95  # Discount factor\n",
    "        self.epsilon = 1.0  # Exploration rate\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.001\n",
    "        self.model = DQN(state_size, action_size)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if random.uniform(0, 1) < self.epsilon:\n",
    "            return random.choice(list(ACTIONS.keys()))\n",
    "        state = torch.FloatTensor(state).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            q_values = self.model(state)\n",
    "        return torch.argmax(q_values).item()\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        if len(self.memory) < batch_size:\n",
    "            return\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                next_state_tensor = torch.FloatTensor(next_state).unsqueeze(0)\n",
    "                target += self.gamma * torch.max(self.model(next_state_tensor)).item()\n",
    "\n",
    "            state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "            target_tensor = self.model(state_tensor).clone().detach()\n",
    "            target_tensor[0][action] = target\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.model(state_tensor)\n",
    "            loss = self.criterion(output, target_tensor)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "598b3f1d-a368-4d31-a831-dd215d28d1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8400\\3109401411.py:4: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  float(data.loc[index, 'Close']),\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8400\\3109401411.py:5: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  float(data.loc[index, 'SMA_5']),\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8400\\3109401411.py:6: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  float(data.loc[index, 'SMA_20']),\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8400\\3109401411.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  float(data.loc[index, 'Returns'])\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8400\\2218621516.py:17: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  price = float(self.data.loc[self.index, 'Close'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1/500, Total Reward: -9898.712795257568\n",
      "Episode 2/500, Total Reward: -9828.02758026123\n",
      "Episode 3/500, Total Reward: -9860.240871429443\n",
      "Episode 4/500, Total Reward: -9881.174446105957\n",
      "Episode 5/500, Total Reward: -9867.727638244629\n",
      "Episode 6/500, Total Reward: -9807.3980178833\n",
      "Episode 7/500, Total Reward: 13397.107837677002\n",
      "Episode 8/500, Total Reward: -9772.418895721436\n",
      "Episode 9/500, Total Reward: -9976.891929626465\n",
      "Episode 10/500, Total Reward: -9871.365921020508\n",
      "Episode 11/500, Total Reward: -9919.633937835693\n",
      "Episode 12/500, Total Reward: -9866.341110229492\n",
      "Episode 13/500, Total Reward: -9917.672519683838\n",
      "Episode 14/500, Total Reward: -9843.071510314941\n",
      "Episode 15/500, Total Reward: -9778.467330932617\n",
      "Episode 16/500, Total Reward: 9370.282402038574\n",
      "Episode 17/500, Total Reward: 11867.833972930908\n",
      "Episode 18/500, Total Reward: -2169.7994422912598\n",
      "Episode 19/500, Total Reward: -9994.555076599121\n",
      "Episode 20/500, Total Reward: -9925.462921142578\n",
      "Episode 21/500, Total Reward: -9757.716186523438\n",
      "Episode 22/500, Total Reward: -9857.660186767578\n",
      "Episode 23/500, Total Reward: -9975.868682861328\n",
      "Episode 24/500, Total Reward: -9848.330173492432\n",
      "Episode 25/500, Total Reward: -9935.965454101562\n",
      "Episode 26/500, Total Reward: 5851.1932945251465\n",
      "Episode 27/500, Total Reward: -9998.216487884521\n",
      "Episode 28/500, Total Reward: -9835.04409790039\n",
      "Episode 29/500, Total Reward: 8950.125457763672\n",
      "Episode 30/500, Total Reward: -9786.458557128906\n",
      "Episode 31/500, Total Reward: -9821.890350341797\n",
      "Episode 32/500, Total Reward: -9843.124374389648\n",
      "Episode 33/500, Total Reward: 1313.6093444824219\n",
      "Episode 34/500, Total Reward: 8431.857330322266\n",
      "Episode 35/500, Total Reward: -9821.709865570068\n",
      "Episode 36/500, Total Reward: 3999.832359313965\n",
      "Episode 37/500, Total Reward: -9911.099704742432\n",
      "Episode 38/500, Total Reward: -9939.240173339844\n",
      "Episode 39/500, Total Reward: -9808.908752441406\n",
      "Episode 40/500, Total Reward: 3394.725372314453\n",
      "Episode 41/500, Total Reward: -9855.472854614258\n",
      "Episode 42/500, Total Reward: -9928.49089050293\n",
      "Episode 43/500, Total Reward: -9834.667232513428\n",
      "Episode 44/500, Total Reward: -9790.489597320557\n",
      "Episode 45/500, Total Reward: 9255.349681854248\n",
      "Episode 46/500, Total Reward: 1138.3080368041992\n",
      "Episode 47/500, Total Reward: -9849.560611724854\n",
      "Episode 48/500, Total Reward: -9998.311561584473\n",
      "Episode 49/500, Total Reward: 13977.952285766602\n",
      "Episode 50/500, Total Reward: -9927.207733154297\n",
      "Episode 51/500, Total Reward: 387.9636535644531\n",
      "Episode 52/500, Total Reward: -9820.669486999512\n",
      "Episode 53/500, Total Reward: 5280.979419708252\n",
      "Episode 54/500, Total Reward: -9927.876319885254\n",
      "Episode 55/500, Total Reward: -9829.47146987915\n",
      "Episode 56/500, Total Reward: -3581.2008514404297\n",
      "Episode 57/500, Total Reward: -9826.739616394043\n",
      "Episode 58/500, Total Reward: -9869.881130218506\n",
      "Episode 59/500, Total Reward: -9862.54972076416\n",
      "Episode 60/500, Total Reward: -1648.8135871887207\n",
      "Episode 61/500, Total Reward: 11020.389385223389\n",
      "Episode 62/500, Total Reward: -9938.68046951294\n",
      "Episode 63/500, Total Reward: -9853.185791015625\n",
      "Episode 64/500, Total Reward: -9938.061019897461\n",
      "Episode 65/500, Total Reward: -9747.416149139404\n",
      "Episode 66/500, Total Reward: -9930.536575317383\n",
      "Episode 67/500, Total Reward: -9942.323680877686\n",
      "Episode 68/500, Total Reward: 12440.696449279785\n",
      "Episode 69/500, Total Reward: -9763.678726196289\n",
      "Episode 70/500, Total Reward: -9916.239204406738\n",
      "Episode 71/500, Total Reward: -9984.81122970581\n",
      "Episode 72/500, Total Reward: -9807.973812103271\n",
      "Episode 73/500, Total Reward: -9916.073585510254\n",
      "Episode 74/500, Total Reward: -9986.189304351807\n",
      "Episode 75/500, Total Reward: -9833.919593811035\n",
      "Episode 76/500, Total Reward: -9904.293762207031\n",
      "Episode 77/500, Total Reward: -9833.2763671875\n",
      "Episode 78/500, Total Reward: -9939.94278717041\n",
      "Episode 79/500, Total Reward: -9839.578937530518\n",
      "Episode 80/500, Total Reward: -9893.696014404297\n",
      "Episode 81/500, Total Reward: -9977.17501449585\n",
      "Episode 82/500, Total Reward: -9800.47632598877\n",
      "Episode 83/500, Total Reward: -9827.399383544922\n",
      "Episode 84/500, Total Reward: -9821.584548950195\n",
      "Episode 85/500, Total Reward: -9891.713905334473\n",
      "Episode 86/500, Total Reward: -9929.176452636719\n",
      "Episode 87/500, Total Reward: 7920.697532653809\n",
      "Episode 88/500, Total Reward: -9787.096286773682\n",
      "Episode 89/500, Total Reward: 4231.68505859375\n",
      "Episode 90/500, Total Reward: -9904.501556396484\n",
      "Episode 91/500, Total Reward: 3436.5045471191406\n",
      "Episode 92/500, Total Reward: -9911.412612915039\n",
      "Episode 93/500, Total Reward: -9748.894172668457\n",
      "Episode 94/500, Total Reward: -9801.866340637207\n",
      "Episode 95/500, Total Reward: -9885.485061645508\n",
      "Episode 96/500, Total Reward: -9868.208805084229\n",
      "Episode 97/500, Total Reward: -9918.901840209961\n",
      "Episode 98/500, Total Reward: -9779.784156799316\n",
      "Episode 99/500, Total Reward: 10624.905590057373\n",
      "Episode 100/500, Total Reward: 25657.883155822754\n",
      "Episode 101/500, Total Reward: -9933.980381011963\n",
      "Episode 102/500, Total Reward: -9829.679096221924\n",
      "Episode 103/500, Total Reward: -9804.495105743408\n",
      "Episode 104/500, Total Reward: -9820.153778076172\n",
      "Episode 105/500, Total Reward: -9878.01050567627\n",
      "Episode 106/500, Total Reward: -9947.388809204102\n",
      "Episode 107/500, Total Reward: -9944.316047668457\n",
      "Episode 108/500, Total Reward: -1769.0973167419434\n",
      "Episode 109/500, Total Reward: -9998.898330688477\n",
      "Episode 110/500, Total Reward: -9811.743019104004\n",
      "Episode 111/500, Total Reward: -9744.422637939453\n",
      "Episode 112/500, Total Reward: -9870.404922485352\n",
      "Episode 113/500, Total Reward: -9842.584568023682\n",
      "Episode 114/500, Total Reward: -9769.065689086914\n",
      "Episode 115/500, Total Reward: -9871.26615524292\n",
      "Episode 116/500, Total Reward: -9792.901145935059\n",
      "Episode 117/500, Total Reward: 10512.750804901123\n",
      "Episode 118/500, Total Reward: -9983.752578735352\n",
      "Episode 119/500, Total Reward: -9876.27509689331\n",
      "Episode 120/500, Total Reward: -9931.183048248291\n",
      "Episode 121/500, Total Reward: -9844.890197753906\n",
      "Episode 122/500, Total Reward: -9910.61209487915\n",
      "Episode 123/500, Total Reward: -9816.817226409912\n",
      "Episode 124/500, Total Reward: -9862.126453399658\n",
      "Episode 125/500, Total Reward: -9844.357273101807\n",
      "Episode 126/500, Total Reward: -9781.753677368164\n",
      "Episode 127/500, Total Reward: -9833.85118484497\n",
      "Episode 128/500, Total Reward: -9874.82292175293\n",
      "Episode 129/500, Total Reward: -9886.010906219482\n",
      "Episode 130/500, Total Reward: -9981.272415161133\n",
      "Episode 131/500, Total Reward: -9897.866245269775\n",
      "Episode 132/500, Total Reward: -9936.424171447754\n",
      "Episode 133/500, Total Reward: -9774.649570465088\n",
      "Episode 134/500, Total Reward: -9855.333591461182\n",
      "Episode 135/500, Total Reward: -1786.548698425293\n",
      "Episode 136/500, Total Reward: -9945.469791412354\n",
      "Episode 137/500, Total Reward: -9877.910202026367\n",
      "Episode 138/500, Total Reward: -9861.38890838623\n",
      "Episode 139/500, Total Reward: -9836.829086303711\n",
      "Episode 140/500, Total Reward: 8226.248497009277\n",
      "Episode 141/500, Total Reward: -9853.310138702393\n",
      "Episode 142/500, Total Reward: -9885.033592224121\n",
      "Episode 143/500, Total Reward: -9803.32409286499\n",
      "Episode 144/500, Total Reward: -9856.801006317139\n",
      "Episode 145/500, Total Reward: -9862.043472290039\n",
      "Episode 146/500, Total Reward: -9881.515705108643\n",
      "Episode 147/500, Total Reward: -9880.871040344238\n",
      "Episode 148/500, Total Reward: -9837.59716796875\n",
      "Episode 149/500, Total Reward: 1265.591236114502\n",
      "Episode 150/500, Total Reward: -9769.618885040283\n",
      "Episode 151/500, Total Reward: -9837.140979766846\n",
      "Episode 152/500, Total Reward: 19943.50202178955\n",
      "Episode 153/500, Total Reward: -9928.310726165771\n",
      "Episode 154/500, Total Reward: -9843.121906280518\n",
      "Episode 155/500, Total Reward: -9847.196254730225\n",
      "Episode 156/500, Total Reward: -9822.757682800293\n",
      "Episode 157/500, Total Reward: -9784.80530166626\n",
      "Episode 158/500, Total Reward: -9906.11372756958\n",
      "Episode 159/500, Total Reward: -9886.396076202393\n",
      "Episode 160/500, Total Reward: -9862.056625366211\n",
      "Episode 161/500, Total Reward: 265.40829849243164\n",
      "Episode 162/500, Total Reward: -9917.296829223633\n",
      "Episode 163/500, Total Reward: -9939.09449005127\n",
      "Episode 164/500, Total Reward: -9942.419815063477\n",
      "Episode 165/500, Total Reward: -9770.84708404541\n",
      "Episode 166/500, Total Reward: -9930.765411376953\n",
      "Episode 167/500, Total Reward: 6139.883087158203\n",
      "Episode 168/500, Total Reward: -9875.971939086914\n",
      "Episode 169/500, Total Reward: -9922.973350524902\n",
      "Episode 170/500, Total Reward: -9857.186248779297\n",
      "Episode 171/500, Total Reward: 11565.73178100586\n",
      "Episode 172/500, Total Reward: -9887.593044281006\n",
      "Episode 173/500, Total Reward: 11783.61307144165\n",
      "Episode 174/500, Total Reward: -9799.599296569824\n",
      "Episode 175/500, Total Reward: -9831.240070343018\n",
      "Episode 176/500, Total Reward: -9928.207599639893\n",
      "Episode 177/500, Total Reward: 6839.848648071289\n",
      "Episode 178/500, Total Reward: -9975.119262695312\n",
      "Episode 179/500, Total Reward: -9774.255828857422\n",
      "Episode 180/500, Total Reward: -9921.033805847168\n",
      "Episode 181/500, Total Reward: -9908.2320022583\n",
      "Episode 182/500, Total Reward: 940.3005142211914\n",
      "Episode 183/500, Total Reward: -9970.932926177979\n",
      "Episode 184/500, Total Reward: -9755.824661254883\n",
      "Episode 185/500, Total Reward: -9767.38924407959\n",
      "Episode 186/500, Total Reward: -9758.457256317139\n",
      "Episode 187/500, Total Reward: 2132.744815826416\n",
      "Episode 188/500, Total Reward: -9970.523151397705\n",
      "Episode 189/500, Total Reward: -9945.00520324707\n",
      "Episode 190/500, Total Reward: 3459.493927001953\n",
      "Episode 191/500, Total Reward: -9929.19234085083\n",
      "Episode 192/500, Total Reward: -9909.396907806396\n",
      "Episode 193/500, Total Reward: -9860.326171875\n",
      "Episode 194/500, Total Reward: -9927.54712677002\n",
      "Episode 195/500, Total Reward: 5910.51383972168\n",
      "Episode 196/500, Total Reward: 3147.014560699463\n",
      "Episode 197/500, Total Reward: 17062.393714904785\n",
      "Episode 198/500, Total Reward: 12072.315399169922\n",
      "Episode 199/500, Total Reward: -9802.864051818848\n",
      "Episode 200/500, Total Reward: -9867.545085906982\n",
      "Episode 201/500, Total Reward: -9855.39741897583\n",
      "Episode 202/500, Total Reward: 4525.613716125488\n",
      "Episode 203/500, Total Reward: -9877.228889465332\n",
      "Episode 204/500, Total Reward: -9941.285484313965\n",
      "Episode 205/500, Total Reward: 12898.538970947266\n",
      "Episode 206/500, Total Reward: -9810.098136901855\n",
      "Episode 207/500, Total Reward: 2027.5319213867188\n",
      "Episode 208/500, Total Reward: 3066.3595809936523\n",
      "Episode 209/500, Total Reward: -9820.14930343628\n",
      "Episode 210/500, Total Reward: -9847.762100219727\n",
      "Episode 211/500, Total Reward: -9928.05493927002\n",
      "Episode 212/500, Total Reward: -9773.419528961182\n",
      "Episode 213/500, Total Reward: -9738.833709716797\n",
      "Episode 214/500, Total Reward: 1131.5766487121582\n",
      "Episode 215/500, Total Reward: 7212.883926391602\n",
      "Episode 216/500, Total Reward: -9859.87865447998\n",
      "Episode 217/500, Total Reward: -9873.663917541504\n",
      "Episode 218/500, Total Reward: -9862.917728424072\n",
      "Episode 219/500, Total Reward: -9846.10258102417\n",
      "Episode 220/500, Total Reward: -9935.868659973145\n",
      "Episode 221/500, Total Reward: 924.3575057983398\n",
      "Episode 222/500, Total Reward: -9853.155475616455\n",
      "Episode 223/500, Total Reward: -9761.085372924805\n",
      "Episode 224/500, Total Reward: -1576.3656120300293\n",
      "Episode 225/500, Total Reward: 1470.822509765625\n",
      "Episode 226/500, Total Reward: 1925.2018241882324\n",
      "Episode 227/500, Total Reward: -2915.102653503418\n",
      "Episode 228/500, Total Reward: 711.3582305908203\n",
      "Episode 229/500, Total Reward: -161.52460098266602\n",
      "Episode 230/500, Total Reward: 1044.384449005127\n",
      "Episode 231/500, Total Reward: 3133.0083389282227\n",
      "Episode 232/500, Total Reward: 266.0428466796875\n",
      "Episode 233/500, Total Reward: 9006.94465637207\n",
      "Episode 234/500, Total Reward: -618.1783981323242\n",
      "Episode 235/500, Total Reward: -948.6605606079102\n",
      "Episode 236/500, Total Reward: -766.3775024414062\n",
      "Episode 237/500, Total Reward: 2847.597438812256\n",
      "Episode 238/500, Total Reward: 3304.969051361084\n",
      "Episode 239/500, Total Reward: -321.7773780822754\n",
      "Episode 240/500, Total Reward: 3056.770706176758\n",
      "Episode 241/500, Total Reward: -9922.640533447266\n",
      "Episode 242/500, Total Reward: 15832.44429397583\n",
      "Episode 243/500, Total Reward: -952.8539352416992\n",
      "Episode 244/500, Total Reward: 10084.135040283203\n",
      "Episode 245/500, Total Reward: -9798.861274719238\n",
      "Episode 246/500, Total Reward: 7431.854774475098\n",
      "Episode 247/500, Total Reward: -9914.016445159912\n",
      "Episode 248/500, Total Reward: -9896.107494354248\n",
      "Episode 249/500, Total Reward: 4444.199974060059\n",
      "Episode 250/500, Total Reward: -9838.522533416748\n",
      "Episode 251/500, Total Reward: 12792.146202087402\n",
      "Episode 252/500, Total Reward: -9854.451168060303\n",
      "Episode 253/500, Total Reward: -9932.176078796387\n",
      "Episode 254/500, Total Reward: -9838.548080444336\n",
      "Episode 255/500, Total Reward: -9792.025199890137\n",
      "Episode 256/500, Total Reward: -9991.382232666016\n",
      "Episode 257/500, Total Reward: -9995.27025604248\n",
      "Episode 258/500, Total Reward: -9847.759574890137\n",
      "Episode 259/500, Total Reward: -9940.035205841064\n",
      "Episode 260/500, Total Reward: -9814.164951324463\n",
      "Episode 261/500, Total Reward: -9938.343204498291\n",
      "Episode 262/500, Total Reward: 3178.167709350586\n",
      "Episode 263/500, Total Reward: 9592.007095336914\n",
      "Episode 264/500, Total Reward: -9762.371704101562\n",
      "Episode 265/500, Total Reward: -9985.066635131836\n",
      "Episode 266/500, Total Reward: -9844.912132263184\n",
      "Episode 267/500, Total Reward: -9969.36888885498\n",
      "Episode 268/500, Total Reward: -9862.42380142212\n",
      "Episode 269/500, Total Reward: -9784.672218322754\n",
      "Episode 270/500, Total Reward: -9857.48306274414\n",
      "Episode 271/500, Total Reward: -9919.709308624268\n",
      "Episode 272/500, Total Reward: -1637.926097869873\n",
      "Episode 273/500, Total Reward: -9846.399391174316\n",
      "Episode 274/500, Total Reward: 4234.823356628418\n",
      "Episode 275/500, Total Reward: -9802.750198364258\n",
      "Episode 276/500, Total Reward: -9847.590385437012\n",
      "Episode 277/500, Total Reward: -9931.915775299072\n",
      "Episode 278/500, Total Reward: -9925.589225769043\n",
      "Episode 279/500, Total Reward: -9977.439434051514\n",
      "Episode 280/500, Total Reward: 1259.101390838623\n",
      "Episode 281/500, Total Reward: -677.5788116455078\n",
      "Episode 282/500, Total Reward: 446.5276298522949\n",
      "Episode 283/500, Total Reward: -774.6900024414062\n",
      "Episode 284/500, Total Reward: 335.07575607299805\n",
      "Episode 285/500, Total Reward: 499.55531311035156\n",
      "Episode 286/500, Total Reward: 604.0857009887695\n",
      "Episode 287/500, Total Reward: 1375.6332740783691\n",
      "Episode 288/500, Total Reward: -1570.3991165161133\n",
      "Episode 289/500, Total Reward: 1017.924560546875\n",
      "Episode 290/500, Total Reward: 3957.250419616699\n",
      "Episode 291/500, Total Reward: 1671.2123756408691\n",
      "Episode 292/500, Total Reward: -9969.917556762695\n",
      "Episode 293/500, Total Reward: 1657.461570739746\n",
      "Episode 294/500, Total Reward: -1924.6423263549805\n",
      "Episode 295/500, Total Reward: 1462.325927734375\n",
      "Episode 296/500, Total Reward: 2455.8304138183594\n",
      "Episode 297/500, Total Reward: 2038.8251762390137\n",
      "Episode 298/500, Total Reward: -993.6693878173828\n",
      "Episode 299/500, Total Reward: -9866.851211547852\n",
      "Episode 300/500, Total Reward: -9993.608413696289\n",
      "Episode 301/500, Total Reward: -9795.76082611084\n",
      "Episode 302/500, Total Reward: 2170.7401580810547\n",
      "Episode 303/500, Total Reward: -9875.037117004395\n",
      "Episode 304/500, Total Reward: -9994.66527557373\n",
      "Episode 305/500, Total Reward: -9803.988628387451\n",
      "Episode 306/500, Total Reward: -9934.966659545898\n",
      "Episode 307/500, Total Reward: -9769.67578125\n",
      "Episode 308/500, Total Reward: -9805.494274139404\n",
      "Episode 309/500, Total Reward: -9869.380187988281\n",
      "Episode 310/500, Total Reward: -9799.743412017822\n",
      "Episode 311/500, Total Reward: -9793.944473266602\n",
      "Episode 312/500, Total Reward: -9994.362735748291\n",
      "Episode 313/500, Total Reward: -224.728759765625\n",
      "Episode 314/500, Total Reward: -9869.70991897583\n",
      "Episode 315/500, Total Reward: -9939.688186645508\n",
      "Episode 316/500, Total Reward: 42.46460723876953\n",
      "Episode 317/500, Total Reward: -9980.607398986816\n",
      "Episode 318/500, Total Reward: -9993.400009155273\n",
      "Episode 319/500, Total Reward: -527.2340316772461\n",
      "Episode 320/500, Total Reward: -9999.395107269287\n",
      "Episode 321/500, Total Reward: -9866.121280670166\n",
      "Episode 322/500, Total Reward: -9831.845512390137\n",
      "Episode 323/500, Total Reward: 4007.581817626953\n",
      "Episode 324/500, Total Reward: -9863.244667053223\n",
      "Episode 325/500, Total Reward: -9857.503692626953\n",
      "Episode 326/500, Total Reward: -9845.59243774414\n",
      "Episode 327/500, Total Reward: 7688.519058227539\n",
      "Episode 328/500, Total Reward: 6692.483978271484\n",
      "Episode 329/500, Total Reward: 2243.451271057129\n",
      "Episode 330/500, Total Reward: -9801.50379562378\n",
      "Episode 331/500, Total Reward: -127.97048950195312\n",
      "Episode 332/500, Total Reward: -9865.264251708984\n",
      "Episode 333/500, Total Reward: -9971.867614746094\n",
      "Episode 334/500, Total Reward: 2265.283515930176\n",
      "Episode 335/500, Total Reward: -9855.646987915039\n",
      "Episode 336/500, Total Reward: -9828.477325439453\n",
      "Episode 337/500, Total Reward: 6290.222915649414\n",
      "Episode 338/500, Total Reward: -9998.555824279785\n",
      "Episode 339/500, Total Reward: 9122.792739868164\n",
      "Episode 340/500, Total Reward: 15153.675064086914\n",
      "Episode 341/500, Total Reward: 3159.55904006958\n",
      "Episode 342/500, Total Reward: -9849.395889282227\n",
      "Episode 343/500, Total Reward: 8621.822277069092\n",
      "Episode 344/500, Total Reward: -9780.349880218506\n",
      "Episode 345/500, Total Reward: 5523.678527832031\n",
      "Episode 346/500, Total Reward: -9796.827087402344\n",
      "Episode 347/500, Total Reward: 4433.527648925781\n",
      "Episode 348/500, Total Reward: -9816.43363571167\n",
      "Episode 349/500, Total Reward: -9819.997497558594\n",
      "Episode 350/500, Total Reward: -9804.776592254639\n",
      "Episode 351/500, Total Reward: 11554.586143493652\n",
      "Episode 352/500, Total Reward: -9811.402389526367\n",
      "Episode 353/500, Total Reward: 13192.48450088501\n",
      "Episode 354/500, Total Reward: -9864.330749511719\n",
      "Episode 355/500, Total Reward: -9752.481330871582\n",
      "Episode 356/500, Total Reward: -9810.107521057129\n",
      "Episode 357/500, Total Reward: 371.5407257080078\n",
      "Episode 358/500, Total Reward: -9829.191593170166\n",
      "Episode 359/500, Total Reward: -9814.16869354248\n",
      "Episode 360/500, Total Reward: -9870.466636657715\n",
      "Episode 361/500, Total Reward: -9805.868957519531\n",
      "Episode 362/500, Total Reward: -9805.212043762207\n",
      "Episode 363/500, Total Reward: -9932.054782867432\n",
      "Episode 364/500, Total Reward: -9789.442268371582\n",
      "Episode 365/500, Total Reward: -9817.527793884277\n",
      "Episode 366/500, Total Reward: -9786.621147155762\n",
      "Episode 367/500, Total Reward: 7313.336540222168\n",
      "Episode 368/500, Total Reward: 10303.202583312988\n",
      "Episode 369/500, Total Reward: -9998.210391998291\n",
      "Episode 370/500, Total Reward: -9822.86693572998\n",
      "Episode 371/500, Total Reward: 13604.138084411621\n",
      "Episode 372/500, Total Reward: -9869.539501190186\n",
      "Episode 373/500, Total Reward: -9786.800682067871\n",
      "Episode 374/500, Total Reward: -9836.880668640137\n",
      "Episode 375/500, Total Reward: 3571.289993286133\n",
      "Episode 376/500, Total Reward: -9849.348846435547\n",
      "Episode 377/500, Total Reward: -9847.205436706543\n",
      "Episode 378/500, Total Reward: -9991.153907775879\n",
      "Episode 379/500, Total Reward: -9934.128517150879\n",
      "Episode 380/500, Total Reward: -9761.042964935303\n",
      "Episode 381/500, Total Reward: -9934.86994934082\n",
      "Episode 382/500, Total Reward: -9857.889877319336\n",
      "Episode 383/500, Total Reward: -9937.18843460083\n",
      "Episode 384/500, Total Reward: -9786.786712646484\n",
      "Episode 385/500, Total Reward: -9870.303211212158\n",
      "Episode 386/500, Total Reward: -9847.41219329834\n",
      "Episode 387/500, Total Reward: -9928.20612335205\n",
      "Episode 388/500, Total Reward: -9826.544342041016\n",
      "Episode 389/500, Total Reward: 1317.6987991333008\n",
      "Episode 390/500, Total Reward: 10964.590057373047\n",
      "Episode 391/500, Total Reward: 8200.37561416626\n",
      "Episode 392/500, Total Reward: -9777.203895568848\n",
      "Episode 393/500, Total Reward: -9860.924362182617\n",
      "Episode 394/500, Total Reward: -9948.74633026123\n",
      "Episode 395/500, Total Reward: -9840.100860595703\n",
      "Episode 396/500, Total Reward: 6658.234771728516\n",
      "Episode 397/500, Total Reward: -9965.269157409668\n",
      "Episode 398/500, Total Reward: -9874.632457733154\n",
      "Episode 399/500, Total Reward: 2076.4179611206055\n",
      "Episode 400/500, Total Reward: -9939.218566894531\n",
      "Episode 401/500, Total Reward: -9957.870162963867\n",
      "Episode 402/500, Total Reward: 1255.8723907470703\n",
      "Episode 403/500, Total Reward: -9759.36459350586\n",
      "Episode 404/500, Total Reward: -654.0981216430664\n",
      "Episode 405/500, Total Reward: 1061.443748474121\n",
      "Episode 406/500, Total Reward: 134.1808090209961\n",
      "Episode 407/500, Total Reward: -9991.229347229004\n",
      "Episode 408/500, Total Reward: -1537.711784362793\n",
      "Episode 409/500, Total Reward: 915.053840637207\n",
      "Episode 410/500, Total Reward: 1380.6005973815918\n",
      "Episode 411/500, Total Reward: -12.942169189453125\n",
      "Episode 412/500, Total Reward: -9954.343437194824\n",
      "Episode 413/500, Total Reward: -353.2974853515625\n",
      "Episode 414/500, Total Reward: 652.906982421875\n",
      "Episode 415/500, Total Reward: 2567.725570678711\n",
      "Episode 416/500, Total Reward: -1092.1619110107422\n",
      "Episode 417/500, Total Reward: -9957.960662841797\n",
      "Episode 418/500, Total Reward: -9911.404964447021\n",
      "Episode 419/500, Total Reward: 2187.354217529297\n",
      "Episode 420/500, Total Reward: 2048.6182708740234\n",
      "Episode 421/500, Total Reward: -1115.134017944336\n",
      "Episode 422/500, Total Reward: 19588.44563293457\n",
      "Episode 423/500, Total Reward: -602.0628395080566\n",
      "Episode 424/500, Total Reward: -9803.386734008789\n",
      "Episode 425/500, Total Reward: -9890.744895935059\n",
      "Episode 426/500, Total Reward: -9946.684272766113\n",
      "Episode 427/500, Total Reward: 11.941131591796875\n",
      "Episode 428/500, Total Reward: -9766.885593414307\n",
      "Episode 429/500, Total Reward: -9770.192066192627\n",
      "Episode 430/500, Total Reward: 1652.3892822265625\n",
      "Episode 431/500, Total Reward: -9937.757019042969\n",
      "Episode 432/500, Total Reward: 11525.670227050781\n",
      "Episode 433/500, Total Reward: 2921.061164855957\n",
      "Episode 434/500, Total Reward: -9873.623641967773\n",
      "Episode 435/500, Total Reward: 7318.807662963867\n",
      "Episode 436/500, Total Reward: -1227.951271057129\n",
      "Episode 437/500, Total Reward: -9996.8002243042\n",
      "Episode 438/500, Total Reward: 8329.073066711426\n",
      "Episode 439/500, Total Reward: 5376.615219116211\n",
      "Episode 440/500, Total Reward: -9823.826934814453\n",
      "Episode 441/500, Total Reward: -9978.414226531982\n",
      "Episode 442/500, Total Reward: -9749.633605957031\n",
      "Episode 443/500, Total Reward: -9886.115272521973\n",
      "Episode 444/500, Total Reward: -9746.922073364258\n",
      "Episode 445/500, Total Reward: 6566.953346252441\n",
      "Episode 446/500, Total Reward: 11141.296768188477\n",
      "Episode 447/500, Total Reward: -9892.667999267578\n",
      "Episode 448/500, Total Reward: -9964.36434173584\n",
      "Episode 449/500, Total Reward: 11174.014366149902\n",
      "Episode 450/500, Total Reward: 8237.79118347168\n",
      "Episode 451/500, Total Reward: -9900.877197265625\n",
      "Episode 452/500, Total Reward: 1506.01900100708\n",
      "Episode 453/500, Total Reward: -9880.74787902832\n",
      "Episode 454/500, Total Reward: -9990.255851745605\n",
      "Episode 455/500, Total Reward: -9981.461051940918\n",
      "Episode 456/500, Total Reward: -9879.76908493042\n",
      "Episode 457/500, Total Reward: -9751.309505462646\n",
      "Episode 458/500, Total Reward: 4841.74267578125\n",
      "Episode 459/500, Total Reward: -9862.86595916748\n",
      "Episode 460/500, Total Reward: -9923.508220672607\n",
      "Episode 461/500, Total Reward: 17734.811500549316\n",
      "Episode 462/500, Total Reward: -9868.22477722168\n",
      "Episode 463/500, Total Reward: -9824.164367675781\n",
      "Episode 464/500, Total Reward: 3290.42781829834\n",
      "Episode 465/500, Total Reward: 8773.616432189941\n",
      "Episode 466/500, Total Reward: -9870.568450927734\n",
      "Episode 467/500, Total Reward: -9754.081596374512\n",
      "Episode 468/500, Total Reward: -9866.5902633667\n",
      "Episode 469/500, Total Reward: -9836.803386688232\n",
      "Episode 470/500, Total Reward: -9995.993843078613\n",
      "Episode 471/500, Total Reward: 605.9224014282227\n",
      "Episode 472/500, Total Reward: 7965.399238586426\n",
      "Episode 473/500, Total Reward: -9805.001708984375\n",
      "Episode 474/500, Total Reward: -9760.633209228516\n",
      "Episode 475/500, Total Reward: -9860.56616973877\n",
      "Episode 476/500, Total Reward: 10846.880645751953\n",
      "Episode 477/500, Total Reward: -9867.910095214844\n",
      "Episode 478/500, Total Reward: 1746.0235023498535\n",
      "Episode 479/500, Total Reward: -9999.383728027344\n",
      "Episode 480/500, Total Reward: -9814.064319610596\n",
      "Episode 481/500, Total Reward: -9871.166862487793\n",
      "Episode 482/500, Total Reward: -9930.276126861572\n",
      "Episode 483/500, Total Reward: -9936.5954246521\n",
      "Episode 484/500, Total Reward: -9847.784309387207\n",
      "Episode 485/500, Total Reward: -9890.374599456787\n",
      "Episode 486/500, Total Reward: 3582.506134033203\n",
      "Episode 487/500, Total Reward: -9989.61328125\n",
      "Episode 488/500, Total Reward: -9833.094478607178\n",
      "Episode 489/500, Total Reward: -9888.869487762451\n",
      "Episode 490/500, Total Reward: 3335.567024230957\n",
      "Episode 491/500, Total Reward: 8458.750930786133\n",
      "Episode 492/500, Total Reward: -9856.59602355957\n",
      "Episode 493/500, Total Reward: -9992.951461791992\n",
      "Episode 494/500, Total Reward: -9982.809608459473\n",
      "Episode 495/500, Total Reward: -9814.01400756836\n",
      "Episode 496/500, Total Reward: -9935.291519165039\n",
      "Episode 497/500, Total Reward: -9791.094429016113\n",
      "Episode 498/500, Total Reward: -2877.7130126953125\n",
      "Episode 499/500, Total Reward: -9817.36711883545\n",
      "Episode 500/500, Total Reward: -9910.194103240967\n",
      "Training Complete!\n"
     ]
    }
   ],
   "source": [
    "# train the agent\n",
    "env = TradingEnvironment(data)\n",
    "agent = DQNAgent(state_size=4, action_size=3)\n",
    "batch_size = 32\n",
    "episodes = 500\n",
    "total_rewards = []\n",
    "\n",
    "for episode in range(episodes):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        action = agent.act(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "\n",
    "    agent.replay(batch_size)\n",
    "    total_rewards.append(total_reward)\n",
    "    print(f\"Episode {episode+1}/{episodes}, Total Reward: {total_reward}\")\n",
    "\n",
    "print(\"Training Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2d630af-3c95-498f-8661-8c6caa868d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8400\\3109401411.py:4: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  float(data.loc[index, 'Close']),\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8400\\3109401411.py:5: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  float(data.loc[index, 'SMA_5']),\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8400\\3109401411.py:6: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  float(data.loc[index, 'SMA_20']),\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8400\\3109401411.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  float(data.loc[index, 'Returns'])\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_8400\\2218621516.py:17: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  price = float(self.data.loc[self.index, 'Close'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Balance after testing: $0.37\n",
      "Total Profit: $-9999.63\n"
     ]
    }
   ],
   "source": [
    "# create a fresh environment instance for testing\n",
    "test_env = TradingEnvironment(data)\n",
    "state = test_env.reset()\n",
    "done = False\n",
    "\n",
    "# simulate a trading session using the trained agent\n",
    "while not done:\n",
    "    # always choose the best action (exploitation)\n",
    "    action = agent.act(state)\n",
    "    next_state, reward, done, _ = test_env.step(action)\n",
    "    state = next_state if next_state is not None else state\n",
    "\n",
    "final_balance = test_env.balance\n",
    "profit = final_balance - test_env.initial_balance\n",
    "print(f\"Final Balance after testing: ${final_balance:.2f}\")\n",
    "print(f\"Total Profit: ${profit:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
